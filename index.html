<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mediapipe Hand Tracking</title>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
            background-color: #f4f4f9;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }
        h1 {
            margin: 10px 0;
            font-size: 24px;
            color: #333;
        }
        p {
            margin: 10px 0 20px;
            font-size: 18px;
            color: #555;
        }
        canvas {
            display: block;
            border: 1px solid #ddd;
        }
        video {
            display: none; /* Hide the input video */
        }
    </style>
</head>
<body>
    <h1>Have Fun with the Hand Tracker Model Here</h1>
    <p>Just a preview of the hand tracking model we are using in our project.</p>
    <video class="input_video"></video>
    <canvas class="output_canvas"></canvas>
    <script>
        const videoElement = document.querySelector('.input_video');
        const canvasElement = document.querySelector('.output_canvas');
        const canvasCtx = canvasElement.getContext('2d');

        // Resize canvas to match window size
        function resizeCanvas() {
            canvasElement.width = window.innerWidth;
            canvasElement.height = window.innerHeight;
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas(); // Initial resize

        // Mediapipe Hands Setup
        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`,
        });
        hands.setOptions({
            maxNumHands: 2,
            modelComplexity: 1,
        });

        hands.onResults((results) => {
            // Clear the canvas
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

            // Flip the canvas horizontally
            canvasCtx.save();
            canvasCtx.scale(-1, 1); // Flip horizontally
            canvasCtx.translate(-canvasElement.width, 0); // Shift the flipped image back into view

            // Draw the image onto the flipped canvas
            canvasCtx.drawImage(results.image, 0, 0, canvasElement.width, canvasElement.height);

            // Draw hand landmarks and connectors
            for (const landmarks of results.multiHandLandmarks) {
                drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 5 });
                drawLandmarks(canvasCtx, landmarks, { color: '#FF0000', lineWidth: 2 });
            }

            // Restore canvas state to avoid affecting other drawings
            canvasCtx.restore();
        });

        const camera = new Camera(videoElement, {
            onFrame: async () => {
                await hands.send({ image: videoElement });
            },
            width: 640,
            height: 480,
        });
        camera.start();
    </script>
</body>
</html>
